################################ NAIVE-BAYES SYMPTOM BASED OUTPUT PREDICTION###################################

import numpy as np
import pandas as pd
import pandas as pd 
import io 
from google.colab import files  
uploaded = files.upload()

  
df = pd.read_csv(io.BytesIO(uploaded['Dataset.csv'])) 
print(df)
#df = pd.read_csv("Dataset.csv");
df.dropna()
columnlist = df.columns
uniquevalues = []

for i in columnlist:
    print(i)
    uniquevalues.append(df[i].unique())

dictval = dict(zip(columnlist, uniquevalues))
print(dictval)

keys = list(dictval.keys())
#print(keys)
#print(dictval.values())

inputlist = []
for key, value in dictval.items():
    valstring = str(value)
    string = "Enter " + key + " " + valstring + " :: ";
    inputtext = input(string)
    inputlist.append(inputtext.lower())
inputlist = inputlist[0:len(inputlist) - 1]
index = 0
predictyes = []
predictno = []

prob = df.groupby(keys[-1]).HeartProblem.count()

probyes = prob.yes
probno = prob.no


for i in range(len(keys) -1):
    predictyes.append(sum(np.logical_and(df[keys[i]] == inputlist[i], df[keys[len(keys) - 1]] == 'yes')))
    predictno.append(sum(np.logical_and(df[keys[i]] == inputlist[i], df[keys[len(keys) - 1]] == 'no')))
    
finalprobyes = 1
for i in predictyes:
    finalprobyes = finalprobyes * (i/probyes)
    
finalprobno = 1
for i in predictno:
    finalprobno = finalprobno * (i/probno)

if(finalprobyes > finalprobno):
    print("Heart Diseases Found")
else:
    print("Heart Diseases Not Found")



  #########################################COMPARING ACCURACY WITH ALGORITHMS########################################
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
import io 
import warnings
warnings.simplefilter(action = 'ignore', category= FutureWarning)

from sklearn.externals import joblib
from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import log_loss

from google.colab import files  
uploaded = files.upload()

df= pd.read_csv(io.BytesIO(uploaded['heart_disease.csv'])) 

#df = pd.read_csv("../heart_disease.csv")

# First 5 rows of our data
df.head()

df.target.value_counts()

countNoDisease = len(df[df.target == 0])
countHaveDisease = len(df[df.target == 1])
print("Percentage of Patients Haven't Heart Disease: {:.2f}%".format((countNoDisease / (len(df.target))*100)))
print("Percentage of Patients Have Heart Disease: {:.2f}%".format((countHaveDisease / (len(df.target))*100)))

countFemale = len(df[df.sex == 0])
countMale = len(df[df.sex == 1])
print('')
print("Percentage of Female Patients: {:.2f}%".format((countFemale / (len(df.sex))*100)))
print("Percentage of Male Patients: {:.2f}%".format((countMale / (len(df.sex))*100)))

df.isnull().sum()

## graphical representations ##

sns.countplot(x="target", data=df, palette="bwr")
plt.show()

sns.countplot(x='sex', data=df, palette="mako_r")
plt.xlabel("Sex (0 = female, 1= male)")
plt.show()

# Heart Disease Frequency for Sex
pd.crosstab(df.sex,df.target).plot(kind="bar",figsize=(8,5),color=['#E1C340','#4CD7D0' ])
plt.title('Heart Disease Frequency for Gender',fontsize=20)
plt.xlabel('Sex (0 = Female, 1 = Male)',fontsize=15)
plt.xticks(rotation=0)
plt.legend(["Haven't Disease", "Have Disease"],fontsize=13)
plt.ylabel('Frequency',fontsize=15)
plt.show()

# Heart Disease Frequency According To FBS
pd.crosstab(df.fbs,df.target).plot(kind="bar",figsize=(8,5),color=['#A4E8E0','#F8EA8C' ])
plt.title('Heart Disease Frequency According To FBS',fontsize=20)
plt.xlabel('FBS - (Fasting Blood Sugar > 120 mg/dl) (1 = true; 0 = false)',fontsize=15)
plt.xticks(rotation = 0)
plt.legend(["Haven't Disease", "Have Disease"],fontsize=13)
plt.ylabel('Frequency of Disease or Not',fontsize=15)

# Heart Disease Frequency According To Chest Pain Type
pd.crosstab(df.cp,df.target).plot(kind="bar",figsize=(8,4),color=['yellow','blue' ])
plt.title('Heart Disease Frequency According To Chest Pain Type',fontsize=20)
plt.xlabel('Chest Pain Type',fontsize=15)
plt.xticks(rotation = 0)
plt.ylabel('Frequency of Disease or Not',fontsize=15)
plt.show()
plt.show()

# Maximum Heart Rate v/s age
plt.scatter(x=df.age[df.target==1], y=df.thalach[(df.target==1)], c="yellow")
plt.scatter(x=df.age[df.target==0], y=df.thalach[(df.target==0)])
plt.legend(["Disease", "Not Disease"],fontsize=13)
plt.xlabel("Age",fontsize=15)
plt.ylabel("Maximum Heart Rate",fontsize=15)
plt.show()

# Serum Cholesterol v/s age
plt.scatter(x=df.age[df.target==1], y=df.chol[(df.target==1)], c="blue")
plt.scatter(x=df.age[df.target==0], y=df.chol[(df.target==0)], c="green")
plt.legend(["Disease", "Not Disease"],fontsize=13)
plt.xlabel("Age",fontsize=15)
plt.ylabel("Serum Cholesterol",fontsize=15)
plt.show()

# Blood Pressure v/s age
plt.scatter(x=df.age[df.target==1], y=df.trestbps[(df.target==1)], c="purple")
plt.scatter(x=df.age[df.target==0], y=df.trestbps[(df.target==0)], c="pink")
plt.legend(["Disease", "Not Disease"],fontsize=13)
plt.xlabel("Age",fontsize=15)
plt.ylabel("Blood Pressure",fontsize=15)
plt.show()


# Plot a bar graph for Gender V/s target
N = 2
ind = np.arange(N)
width = 0.1
fig, ax = plt.subplots(figsize =(8,4))

heart_disease = [93, 72]
rects1 = ax.bar(ind, heart_disease, width, color='g')
no_heart_disease = [114, 24]
rects2 = ax.bar(ind+width, no_heart_disease, width, color='y')

ax.set_ylabel('Scores')
ax.set_title('Gender V/s target')
ax.set_xticks(ind)
ax.set_xticklabels(('Male','Female'))
ax.legend((rects1[0], rects2[0]), ('heart disease', 'no heart disease'))

plt.show()
 
#Pie charts for thal:Thalassemla
# Having heart disease   
labels= 'Normal', 'Fixed defect', 'Reversable defect'
sizes=[6, 130, 28]
colors=['red', 'orange', 'green']

plt.pie(sizes, labels=labels, colors=colors, autopct='%.1f%%', shadow=True, startangle=140)

plt.axis('equal')
plt.title('Thalassemla blood disorder status of patients having heart disease')
plt.show()

# Not having heart disease
labels= 'Normal', 'Fixed defect', 'Reversable defect'
sizes=[12, 36, 89]
colors=['red', 'orange', 'green']

plt.pie(sizes, labels=labels, colors=colors, autopct='%.1f%%', shadow=True, startangle=140)

plt.axis('equal')
plt.title('Thalassemla blood disorder status of patients who do not have heart disease')
plt.show()


## data pre-processing ##
accuracies={}
precision={}
df['age'] = df.age.fillna(df.age.mean())
df['sex'] = df.sex.fillna(df.sex.mean())
df['cp'] = df.cp.fillna(df.cp.mean())
df['trestbps'] = df.trestbps.fillna(df.trestbps.mean())
df['chol'] = df.chol.fillna(df.chol.mean())
df['fbs'] = df.fbs.fillna(df.fbs.mean())
df['restecg'] = df.restecg.fillna(df.restecg.mean())
df['thalach'] = df.thalach.fillna(df.thalach.mean())
df['exang'] = df.exang.fillna(df.exang.mean())
df['slope'] = df.slope.fillna(df.slope.mean())
df['thal'] = df.thal.fillna(df.thal.mean())
df['ca'] = df.ca.fillna(df.ca.mean())
df['target'] = df.target.fillna(df.target.mean())
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

from sklearn.preprocessing import StandardScaler as ss
sc = ss()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

## Decision tree ##
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

from sklearn.tree import DecisionTreeClassifier
classifier = DecisionTreeClassifier()
classifier.fit(X_train, y_train)

# Predicting the Test set results
y_pred = classifier.predict(X_test)

from sklearn.metrics import confusion_matrix
cm_test = confusion_matrix(y_pred, y_test)

y_pred_train = classifier.predict(X_train)
cm_train = confusion_matrix(y_pred_train, y_train)


plt.figure(figsize=(10,8))
plt.subplot(3,3,1)
plt.title("Training set",fontsize=15)
sns.heatmap(cm_train,annot=True,cmap="copper",fmt="d",cbar=False, annot_kws={"size": 24})
plt.subplot(3,3,3)
plt.title("Test set",fontsize=15)
sns.heatmap(cm_test,annot=True,cmap="copper",fmt="d",cbar=False, annot_kws={"size": 24})

print()
acc= (cm_test[0][0] + cm_test[1][1])/len(y_test)
p=(cm_test[1][1]/(cm_test[1][1] + cm_test[1][0]))
precision['Decision Tree'] = p
accuracies['Decision Tree'] = acc
print('Accuracy for training set for Decision Tree = {}'.format((cm_train[0][0] + cm_train[1][1])/len(y_train)))
print('Precision for Decision Tree = {}'.format(p))
print('Accuracy for test set for Decision Tree = {}'.format(acc))
##Random Forest##

X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 8)

from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier()
classifier.fit(X_train, y_train)

# Predicting the Test set results
y_pred = classifier.predict(X_test)

from sklearn.metrics import confusion_matrix
cm_test = confusion_matrix(y_pred, y_test)

y_pred_train = classifier.predict(X_train)
cm_train = confusion_matrix(y_pred_train, y_train)


plt.figure(figsize=(10,8))
plt.subplot(3,3,1)
plt.title("Training set",fontsize=15)
sns.heatmap(cm_train,annot=True,cmap="copper",fmt="d",cbar=False, annot_kws={"size": 24})
plt.subplot(3,3,3)
plt.title("Test set",fontsize=15)
sns.heatmap(cm_test,annot=True,cmap="copper",fmt="d",cbar=False, annot_kws={"size": 24})

print()
p= (cm_test[0][0] + cm_test[1][1])/len(y_test)
acc=(cm_test[1][1]/(cm_test[1][1] + cm_test[1][0]))
precision['Random Forest'] = p
accuracies['Random Forest'] = acc
print('Accuracy for training set for Random Forest = {}'.format((cm_train[0][0] + cm_train[1][1])/len(y_train)))
print('Precision for Random Forest = {}'.format(p))
print('Accuracy for test set for Random Forest = {}'.format(acc))

##SVM##

X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 8)

from sklearn.svm import SVC
#svc_model = svm.SVC(kernel='linear')
svc_model = SVC(C= .1, kernel='linear', gamma= 1)
svc_model.fit(X_train, y_train)

# Predicting the Test set results
y_pred = svc_model.predict(X_test)

from sklearn.metrics import confusion_matrix
cm_test = confusion_matrix(y_pred, y_test)

y_pred_train = classifier.predict(X_train)
cm_train = confusion_matrix(y_pred_train, y_train)


plt.figure(figsize=(10,8))
plt.subplot(3,3,1)
plt.title("Training set",fontsize=15)
sns.heatmap(cm_train,annot=True,cmap="copper",fmt="d",cbar=False, annot_kws={"size": 24})
plt.subplot(3,3,3)
plt.title("Test set",fontsize=15)
sns.heatmap(cm_test,annot=True,cmap="copper",fmt="d",cbar=False, annot_kws={"size": 24})
#
prediction = svc_model.predict(X_test) 
# check the accuracy on the training set 
#print(svc_model.score(X_train, y_train)) 
#print(svc_model.score(X_test, y_test))
#

print()
p= (cm_test[0][0] + cm_test[1][1])/len(y_test)
acc=(cm_test[1][1]/(cm_test[1][1] + cm_test[1][0]))
precision['SVM'] = p
accuracies['SVM'] = acc
#print('Accuracy for training set for SVM = {}'.format((cm_train[0][0] + cm_train[1][1])/len(y_train)))
print('Accuracy for training set for SVM = {}'.format(svc_model.score(X_train, y_train)))
print('Precision for SVM = {}'.format(p))
print('Accuracy for test set for SVM = {}'.format(acc))

## Naive Bayes ##
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, y_train)


# Predicting the Test set results
y_pred = classifier.predict(X_test)

from sklearn.metrics import confusion_matrix
cm_test = confusion_matrix(y_pred, y_test)

y_pred_train = classifier.predict(X_train)
cm_train = confusion_matrix(y_pred_train, y_train)


plt.figure(figsize=(10,8))
plt.subplot(3,3,1)
plt.title("Training set",fontsize=15)
sns.heatmap(cm_train,annot=True,cmap="copper",fmt="d",cbar=False, annot_kws={"size": 24})
plt.subplot(3,3,3)
plt.title("Test set",fontsize=15)
sns.heatmap(cm_test,annot=True,cmap="copper",fmt="d",cbar=False, annot_kws={"size": 24})

print()
acc=(cm_test[0][0] + cm_test[1][1])/len(y_test)
p=(cm_test[1][1]/(cm_test[1][1] + cm_test[1][0]))
precision['Naive Bayes'] = p
accuracies['Naive Bayes'] = acc
print('Accuracy for training set for Naive Bayes = {}'.format((cm_train[0][0] + cm_train[1][1])/len(y_train)))
print('Precision for Naive Bayes = {}'.format(p))
print('Accuracy for test set for Naive Bayes = {}'.format(acc))
##KNN Classifier##

X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors=9)
classifier.fit(X_train,y_train)

# Predicting the Test set results
y_pred = classifier.predict(X_test)

from sklearn.metrics import confusion_matrix
cm_test = confusion_matrix(y_pred, y_test)

y_pred_train = classifier.predict(X_train)
cm_train = confusion_matrix(y_pred_train, y_train)


plt.figure(figsize=(10,8))
plt.subplot(3,3,1)
plt.title("Training set",fontsize=15)
sns.heatmap(cm_train,annot=True,cmap="copper",fmt="d",cbar=False, annot_kws={"size": 24})
plt.subplot(3,3,3)
plt.title("Test set",fontsize=15)
sns.heatmap(cm_test,annot=True,cmap="copper",fmt="d",cbar=False, annot_kws={"size": 24})

print()
acc=(cm_test[0][0] + cm_test[1][1])/len(y_test)
p=(cm_test[1][1]/(cm_test[1][1] + cm_test[1][0]))
precision['KNN Classifier'] = p
accuracies['KNN Classifier'] = acc
print('Accuracy for training set for KNN Classifier = {}'.format((cm_train[0][0] + cm_train[1][1])/len(y_train)))
print('Precision for KNN Classifier = {}'.format(p))
print('Accuracy for test set for KNN Classifier = {}'.format(acc))

## Logistic Regression ##
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression()
classifier.fit(X_train, y_train)

# Predicting the Test set results
y_pred = classifier.predict(X_test)

from sklearn.metrics import confusion_matrix
cm_test = confusion_matrix(y_pred, y_test)

y_pred_train = classifier.predict(X_train)
cm_train = confusion_matrix(y_pred_train, y_train)


plt.figure(figsize=(10,8))
plt.subplot(3,3,1)
plt.title("Training set",fontsize=15)
sns.heatmap(cm_train,annot=True,cmap="copper",fmt="d",cbar=False, annot_kws={"size": 24})
plt.subplot(3,3,3)
plt.title("Test set",fontsize=15)
sns.heatmap(cm_test,annot=True,cmap="copper",fmt="d",cbar=False, annot_kws={"size": 24})

print()
acc=((cm_test[0][0] + cm_test[1][1])/len(y_test))
p=(cm_test[1][1]/(cm_test[1][1] + cm_test[1][0]))
precision['Logistic Regression'] = p
accuracies['Logistic Regression'] = acc
print('Accuracy for training set for Logistic Regression = {}'.format((cm_train[0][0] + cm_train[1][1])/len(y_train)))
print('Precision for Logistic Regression = {}'.format(p))
print('Accuracy for test set for Logistic Regression = {}'.format(acc))

## Comparison ##
colors = ["purple", "green", "orange","yellow","blue","red"]

sns.set_style("whitegrid")
plt.figure(figsize=(10,5))
plt.yticks(np.arange(0,1.0,0.2))
plt.ylabel("Accuracy %",fontsize=15)
plt.xlabel("Algorithms",fontsize=15)
sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette=colors)
plt.show()

colors = ["blue","yellow","green","brown","orange","red"]

sns.set_style("whitegrid")
plt.figure(figsize=(10,5))
plt.yticks(np.arange(0,1.0,0.2))
plt.ylabel("Precision %",fontsize=15)
plt.xlabel("Algorithms",fontsize=15)
sns.barplot(x=list(precision.keys()), y=list(precision.values()), palette=colors)
plt.show()

## ROC curves ##
#ROC is a probability curve and AUC represents the degree or measure of separability.
# loading libraries
from sklearn import datasets
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt

# Creating feature matrix and target vector
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values


# Spliting into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

# Creating classifier
clf_tree = DecisionTreeClassifier(); clf_reg = LogisticRegression(); clf_nb = GaussianNB();clf_rf = RandomForestClassifier();clf_svm=SVC();clf_knn=KNeighborsClassifier();

# Training model
clf_tree.fit(X_train, y_train); clf_reg.fit(X_train, y_train); clf_nb.fit(X_train, y_train);clf_rf.fit(X_train,y_train);clf_knn.fit(X_train,y_train);clf_svm.fit(X_train,y_train);

# Getting predicted probabilities
y_score1 = clf_tree.predict_proba(X_test)[:,1]
y_score2 = clf_reg.predict_proba(X_test)[:,1]
y_score3 = clf_nb.predict_proba(X_test)[:,1]
y_score4 = clf_rf.predict_proba(X_test)[:,1]
y_score5 = clf_rf.predict_proba(X_test)[:,1]
y_score6 = clf_knn.predict_proba(X_test)[:,1]
# Ploting Receiving Operating Characteristic Curve
# Creating true and false positive rates
false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, y_score1)
false_positive_rate2, true_positive_rate2, threshold2 = roc_curve(y_test, y_score2)
false_positive_rate3, true_positive_rate3, threshold3 = roc_curve(y_test, y_score3)
false_positive_rate4, true_positive_rate4, threshold4 = roc_curve(y_test,y_score4)
false_positive_rate5, true_positive_rate5, threshold5 = roc_curve(y_test,y_score5)
false_positive_rate6, true_positive_rate6, threshold6 = roc_curve(y_test,y_score6)
print('roc_auc_score for DecisionTree: ', roc_auc_score(y_test, y_score1))
print('roc_auc_score for Logistic Regression: ', roc_auc_score(y_test, y_score2))
print('roc_auc_score for Naive Bayes: ', roc_auc_score(y_test, y_score3))
print('roc_auc_score for RandomForest:',roc_auc_score(y_test,y_score4))
print('roc_auc_score for SVM:',roc_auc_score(y_test,y_score5))
print('roc_auc_score for KNN Classifier:',roc_auc_score(y_test,y_score6))
# Ploting ROC curves
plt.subplots(1, figsize=(5,4))
plt.title('Receiver Operating Characteristic - DecisionTree',fontsize=18)
plt.plot(false_positive_rate1, true_positive_rate1)
plt.plot([0, 1], ls="--")
plt.plot([0, 0], [1, 0] , c=".7"), plt.plot([1, 1] , c=".7")
plt.ylabel('True Positive Rate',fontsize=15)
plt.xlabel('False Positive Rate',fontsize=15)
plt.show()

plt.subplots(1, figsize=(5,4))
plt.title('Receiver Operating Characteristic - RandomForest',fontsize=18)
plt.plot(false_positive_rate4, true_positive_rate4)
plt.plot([0, 1], ls="--")
plt.plot([0, 0], [1, 0] , c=".7"), plt.plot([1, 1] , c=".7")
plt.ylabel('True Positive Rate',fontsize=15)
plt.xlabel('False Positive Rate',fontsize=15)
plt.show()

plt.subplots(1, figsize=(5,4))
plt.title('Receiver Operating Characteristic - SVM',fontsize=18)
plt.plot(false_positive_rate4, true_positive_rate4)
plt.plot([0, 1], ls="--")
plt.plot([0, 0], [1, 0] , c=".7"), plt.plot([1, 1] , c=".7")
plt.ylabel('True Positive Rate',fontsize=15)
plt.xlabel('False Positive Rate',fontsize=15)
plt.show()


plt.subplots(1, figsize=(5,4))
plt.title('Receiver Operating Characteristic - KNN Classifier',fontsize=18)
plt.plot(false_positive_rate6, true_positive_rate6)
plt.plot([0, 1], ls="--")
plt.plot([0, 0], [1, 0] , c=".7"), plt.plot([1, 1] , c=".7")
plt.ylabel('True Positive Rate',fontsize=15)
plt.xlabel('False Positive Rate',fontsize=15)
plt.show()

#####################################################################################################